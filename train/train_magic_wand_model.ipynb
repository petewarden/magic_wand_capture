{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"(Dec 12) Train a gesture recognition model for microcontroller use","provenance":[{"file_id":"14T_9kKi6tQBmJYmD-ywK_gZB0UIfrkoZ","timestamp":1605631179659},{"file_id":"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/magic_wand/train/train_magic_wand_model.ipynb","timestamp":1581983149998}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"1BtkMGSYQOTQ"},"source":["# Train a gesture recognition model for microcontroller use"]},{"cell_type":"markdown","metadata":{"id":"BaFfr7DHRmGF"},"source":["This notebook demonstrates how to train a 20kb gesture recognition model for [TensorFlow Lite for Microcontrollers](https://tensorflow.org/lite/microcontrollers/overview). It will produce the same model used in the [magic_wand](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/magic_wand) example application.\n","\n","The model is designed to be used with [Google Colaboratory](https://colab.research.google.com).\n","\n","<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/magic_wand/train/train_magic_wand_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/magic_wand/train/train_magic_wand_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>\n"]},{"cell_type":"markdown","metadata":{"id":"xXgS6rxyT7Qk"},"source":["Training is much faster using GPU acceleration. Before you proceed, ensure you are using a GPU runtime by going to **Runtime -> Change runtime type** and selecting **GPU**. Training will take around 5 minutes on a GPU runtime."]},{"cell_type":"markdown","metadata":{"id":"LG6ErX5FRIaV"},"source":["## Configure dependencies\n","\n","Run the following cell to ensure the correct version of TensorFlow is used."]},{"cell_type":"code","metadata":{"id":"h3sE3keZZnMX","executionInfo":{"status":"ok","timestamp":1607813353318,"user_tz":480,"elapsed":417,"user":{"displayName":"Pete Warden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9RGhKK9hlUJPY0U8OJIEUEeTc3V08ZIBIs175=s64","userId":"17073007660171926128"}}},"source":["%tensorflow_version 2.x\n"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STNft9TrfoVh"},"source":["We'll also clone the TensorFlow repository, which contains the training scripts, and copy them into our workspace."]},{"cell_type":"code","metadata":{"id":"ygkWw73dRNda","executionInfo":{"status":"ok","timestamp":1607813953067,"user_tz":480,"elapsed":1660,"user":{"displayName":"Pete Warden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9RGhKK9hlUJPY0U8OJIEUEeTc3V08ZIBIs175=s64","userId":"17073007660171926128"}}},"source":["!cd /content/\n","!rm -rf magic_wand_capture\n","!rm -rf train\n","# Clone the repository from GitHub\n","!git clone --depth 1 -q https://github.com/petewarden/magic_wand_capture\n","# Copy the training scripts into our workspace\n","!cp -r magic_wand_capture/train train"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pXI7R4RehFdU"},"source":["## Prepare the data\n","\n","Next, we'll download the data and extract it into the expected location within the training scripts' directory."]},{"cell_type":"code","metadata":{"id":"W2Sg2AKzVr2L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607814809230,"user_tz":480,"elapsed":596,"user":{"displayName":"Pete Warden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9RGhKK9hlUJPY0U8OJIEUEeTc3V08ZIBIs175=s64","userId":"17073007660171926128"}},"outputId":"fac28f36-a519-46ee-dec6-e5a5ac9e28f5"},"source":["\n","# The scripts must be run from within the train directory\n","%cd /content/train\n","\n","# Download the data we will use to train the model\n","!wget 'http://download.tensorflow.org/models/tflite/magic_wand/gesture_data_v2_2020_03_22.tar.gz'\n","# Extract the data into the train directory\n","!rm -rf gesture_data_v2\n","!tar xvzf gesture_data_v2_2020_03_22.tar.gz 1>/dev/null"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/content/train\n","--2020-12-12 23:13:28--  http://download.tensorflow.org/models/tflite/magic_wand/gesture_data_v2_2020_03_22.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.217.128, 2607:f8b0:400c:c13::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.217.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 278118 (272K) [application/gzip]\n","Saving to: ‘gesture_data_v2_2020_03_22.tar.gz.1’\n","\n","\r          gesture_d   0%[                    ]       0  --.-KB/s               \rgesture_data_v2_202 100%[===================>] 271.60K  --.-KB/s    in 0.001s  \n","\n","2020-12-12 23:13:28 (404 MB/s) - ‘gesture_data_v2_2020_03_22.tar.gz.1’ saved [278118/278118]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DNjukI1Sgl2C"},"source":["We'll then run the scripts that split the data into training, validation, and test sets."]},{"cell_type":"code","metadata":{"id":"CbsfH5UYP0Oh","executionInfo":{"status":"ok","timestamp":1607814814662,"user_tz":480,"elapsed":1993,"user":{"displayName":"Pete Warden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9RGhKK9hlUJPY0U8OJIEUEeTc3V08ZIBIs175=s64","userId":"17073007660171926128"}}},"source":["!mv gesture_data_v2/petewarden* . # good\n","!mv gesture_data_v2/aritrab* . # good\n","!mv gesture_data_v2/aybuke* . # good\n","!mv gesture_data_v2/imellado* . # good\n","!mv gesture_data_v2/jheez* . # good\n","!mv gesture_data_v2/oscarazu* . # good\n","!mv gesture_data_v2/owoowoo* . # good\n","#!mv gesture_data_v2/realmistic* . # bad\n","#!mv gesture_data_v2/stevenchun* . # bad\n","#!mv gesture_data_v2/vladionescu* . # bad\n","\n","!rm -rf gesture_data_v2/*\n","\n","!mv petewarden* gesture_data_v2/\n","!mv aritrab* gesture_data_v2/\n","!mv aybuke* gesture_data_v2/\n","!mv imellado* gesture_data_v2/\n","!mv jheez* gesture_data_v2/\n","!mv oscarazu* gesture_data_v2/\n","!mv owoowoo* gesture_data_v2/\n","#!mv realmistic* gesture_data_v2/\n","#!mv stevenchun* gesture_data_v2/\n","#!mv vladionescu* gesture_data_v2/\n"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBqSVpi6Vxss"},"source":["# The scripts must be run from within the train directory\n","%cd /content/train\n","\n","# Prepare the data\n","!python data_prepare.py\n","!head gesture_data_v2/all_data.json\n","!python data_split.py\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-cmVbFvhTvy"},"source":["## Load TensorBoard\n","\n","Now, we set up TensorBoard so that we can graph our accuracy and loss as training proceeds."]},{"cell_type":"code","metadata":{"id":"CCx6SN9NWRPw"},"source":["# Load TensorBoard\n","%load_ext tensorboard\n","%tensorboard --logdir logs/scalars"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LDxUYgULi5B6"},"source":["# Visualize Training Data\n","\n","Let's graph some of the data that we'll be using to train the model, to help us better understand it."]},{"cell_type":"code","metadata":{"id":"K5lw-D6YpEnt","executionInfo":{"status":"ok","timestamp":1607814015164,"user_tz":480,"elapsed":431,"user":{"displayName":"Pete Warden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9RGhKK9hlUJPY0U8OJIEUEeTc3V08ZIBIs175=s64","userId":"17073007660171926128"}}},"source":["import math\n","\n","def vector_magnitude(vec):\n","  x = vec[0]\n","  y = vec[1]\n","  z = vec[2]\n","  return math.sqrt((x * x) + (y * y) + (z * z))\n","\n","def normalize_vector(vec):\n","  magnitude = vector_magnitude(vec)\n","  x = vec[0]\n","  y = vec[1]\n","  z = vec[2]\n","  normalized_x = x / magnitude\n","  normalized_y = y / magnitude\n","  normalized_z = z / magnitude\n","  return (normalized_x, normalized_y, normalized_z)  \n","\n","def dot_product(a, b):\n","  return (a[0] * b[0], a[1] * b[1], a[2] * b[2])\n","\n","def estimate_gravity_direction(sequence):\n","  x_total = 0.0\n","  y_total = 0.0\n","  z_total = 0.0\n","  for entry in sequence:\n","    x = entry[0]\n","    y = entry[1]\n","    z = entry[2]\n","    x_total += x\n","    y_total += y\n","    z_total += z\n","  return (x_total / len(sequence), y_total / len(sequence), z_total / len(sequence))\n","\n","def remove_gravity_from_acceleration_data(sequence):\n","  gravity_direction = estimate_gravity_direction(sequence)\n","  gravity_x = gravity_direction[0] * 1.0\n","  gravity_y = gravity_direction[1] * 1.0\n","  gravity_z = gravity_direction[2] * 1.0\n","  result = []\n","  for entry in sequence:\n","    x = entry[0]\n","    y = entry[1]\n","    z = entry[2]\n","    normalized_x = x - gravity_x\n","    normalized_y = y - gravity_y\n","    normalized_z = z - gravity_z\n","    result.append([normalized_x, normalized_y, normalized_z])\n","  return result\n","\n","def acceleration_data_into_positions(sequence):\n","  current_x = 0.0\n","  current_y = 0.0\n","  current_z = 0.0\n","  result = []\n","  for entry in sequence:\n","    x_velocity = entry[0]\n","    y_velocity = entry[1]\n","    z_velocity = entry[2]\n","    current_x += x_velocity\n","    current_y += y_velocity\n","    current_z += z_velocity\n","    result.append([current_x, current_y, current_z])\n","  return result\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gc7rpJ7GpJSl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607814022478,"user_tz":480,"elapsed":2440,"user":{"displayName":"Pete Warden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9RGhKK9hlUJPY0U8OJIEUEeTc3V08ZIBIs175=s64","userId":"17073007660171926128"}},"outputId":"e0153b91-f153-4b96-de67-b2ebb76cafc1"},"source":["import data_load\n","\n","data_loader = data_load.DataLoader(\"gesture_data_v2/training_data.json\",\n","        \"gesture_data_v2/validation_data.json\",\n","        \"gesture_data_v2/testing_data.json\", 128)\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["train_data_length:6840\n","valid_data_length:75\n","test_data_length:80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LAIqHC_2jzdl","executionInfo":{"status":"ok","timestamp":1607814044768,"user_tz":480,"elapsed":409,"user":{"displayName":"Pete Warden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9RGhKK9hlUJPY0U8OJIEUEeTc3V08ZIBIs175=s64","userId":"17073007660171926128"}}},"source":["import matplotlib.pyplot as plt\n","import json\n","import data_prepare\n","import ipywidgets as widgets\n","import os.path as path\n","\n","def plot_data(acceleration_data, label):\n","  gravity_direction = estimate_gravity_direction(acceleration_data)\n","  gravity_free_data = remove_gravity_from_acceleration_data(acceleration_data)\n","  position_data = acceleration_data_into_positions(gravity_free_data)\n","\n","  x_array = []\n","  y_array = []\n","  z_array = []\n","  for coords in position_data:\n","    x_array.append(coords[0])\n","    y_array.append(coords[1])\n","    z_array.append(coords[2])\n","\n","  fig = plt.figure(figsize=(12.8, 4.8))\n","  fig.suptitle(label)\n","\n","  ax = fig.add_subplot(131)\n","  ax.set_xlabel('x')\n","  ax.set_ylabel('y')\n","  ax.set_xlim(-20000, 20000)\n","  ax.set_ylim(-25000, 25000)\n","  ax.plot(x_array, y_array)\n","\n","  ax = fig.add_subplot(132)\n","  ax.set_xlabel('x')\n","  ax.set_ylabel('z')\n","  ax.set_xlim(-20000, 20000)\n","  ax.set_ylim(-25000, 25000)\n","  ax.plot(x_array, z_array)\n","\n","  ax = fig.add_subplot(133)\n","  ax.set_xlabel('y')\n","  ax.set_ylabel('z')\n","  ax.set_xlim(-20000, 20000)\n","  ax.set_ylim(-25000, 25000)\n","  ax.plot(y_array, z_array)\n","\n","  plt.show()\n","\n","hand_labels = []\n","labeled_ids = {}\n","if path.exists(\"hand_labels.json\"):\n","  with open(\"hand_labels.json\", \"r\") as file:\n","    for line in file:\n","      dic = json.loads(line)\n","      hand_labels.append(dic)\n","      labeled_ids[dic[\"source_id\"]] = True\n","\n","gesture_data = []\n","with open(\"gesture_data_v2/all_data.json\", \"r\") as file:\n","  for index, line in enumerate(file):\n","    dic = json.loads(line)\n","    gesture_data.append(dic)\n","    example_data = dic[data_load.DATA_NAME]\n","    label = dic[data_load.LABEL_NAME]\n","    source_id = dic[\"source_id\"]\n","    if source_id in labeled_ids or \"hand_label\" in dic:\n","      continue\n","    plot_data(example_data, label + \" : \" + source_id )\n","    toggles = widgets.ToggleButtons(\n","      options=['Unset', 'Wing', 'Slope', 'Ring', 'Other'],\n","      description='Label:',\n","      disabled=False,\n","      button_style='success',\n","      tooltips=['Unset', 'Wing', 'Slope', 'Ring', 'Other'],\n","    )\n","    def on_click(change, source_id = source_id):\n","      global gesture_data\n","      global hand_labels\n","      hand_labels.append({\"source_id\": source_id, \"hand_label\": change['new']})\n","    on_click.index = index\n","    toggles.observe(on_click, 'value')\n","    display(toggles)\n"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8snbwPpqa3-","executionInfo":{"status":"ok","timestamp":1607814051904,"user_tz":480,"elapsed":484,"user":{"displayName":"Pete Warden","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9RGhKK9hlUJPY0U8OJIEUEeTc3V08ZIBIs175=s64","userId":"17073007660171926128"}}},"source":["\n","#data_prepare.write_json_file(hand_labels, \"hand_labels.json\")\n","#!cat hand_labels.json\n"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ERC2Cr4PhaOl"},"source":["## Begin training\n","\n","The following cell will begin the training process. Training will take around 5 minutes on a GPU runtime. You'll see the metrics in TensorBoard after a few epochs."]},{"cell_type":"code","metadata":{"id":"DXmQZgbuWQFO"},"source":["!python train.py --model CNN --data_source v2 --epochs 50"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4gXbVzcXhvGD"},"source":["## Create a C source file\n","\n","The `train.py` script writes a model, `model.tflite`, to the training scripts' directory.\n","\n","In the following cell, we convert this model into a C++ source file we can use with TensorFlow Lite for Microcontrollers."]},{"cell_type":"code","metadata":{"id":"8wgei4OGe3Nz"},"source":["# Install xxd if it is not available\n","!apt-get -qq install xxd\n","# Save the file as a C source file\n","!xxd -i model.tflite > /content/model.cc\n","# Print the source file\n","!cat /content/model.cc"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZqIvNDB1jj5"},"source":[""],"execution_count":null,"outputs":[]}]}